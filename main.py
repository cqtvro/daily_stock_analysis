# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ - ä¸»è°ƒåº¦ç¨‹åº
(ç°ä»£æœåŠ¡å®šåˆ¶ç‰ˆ - é›†æˆå…¨é¢‘æ®µæ¯ç­æ‰«æ)
===================================
"""
import os
import sys

# ä»£ç†é…ç½®
if os.getenv("GITHUB_ACTIONS") != "true":
    pass

import argparse
import logging
import time
from datetime import datetime, timezone, timedelta
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import List, Optional

# å°è¯•å¼•å…¥é£ä¹¦æ–‡æ¡£ç®¡ç†å™¨
try:
    from src.feishu_doc import FeishuDocManager
except ImportError:
    class FeishuDocManager:
        def is_configured(self): return False
        def create_daily_doc(self, title, content): return None

from src.config import get_config, Config
from src.notification import NotificationService
from src.core.pipeline import StockAnalysisPipeline
from src.core.market_review import run_market_review
from src.search_service import SearchService
from src.analyzer import GeminiAnalyzer

# [ç°ä»£æœåŠ¡] å¼•å…¥å…¨é¢‘æ®µæ‰«ææ¢å¤´
try:
    from src.scanner import scan_for_destruction
except ImportError:
    # å…¼å®¹æ€§å¤„ç†
    def scan_for_destruction(limit=3):
        return []

# é…ç½®æ—¥å¿—æ ¼å¼
LOG_FORMAT = '%(asctime)s | %(levelname)-8s | %(name)-20s | %(message)s'
LOG_DATE_FORMAT = '%Y-%m-%d %H:%M:%S'

def setup_logging(debug: bool = False, log_dir: str = "./logs") -> None:
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    level = logging.DEBUG if debug else logging.INFO
    log_path = Path(log_dir)
    log_path.mkdir(parents=True, exist_ok=True)
    today_str = datetime.now().strftime('%Y%m%d')
    log_file = log_path / f"stock_analysis_{today_str}.log"
    
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)
    
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    console_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(console_handler)
    
    # é™ä½ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('google').setLevel(logging.WARNING)

    # å¼ºåˆ¶æ‰“å°ä¸€è¡Œï¼Œç¡®ä¿çœ‹åˆ°æ—¥å¿—ç³»ç»Ÿå¯åŠ¨
    print(f"DEBUG: æ—¥å¿—ç³»ç»Ÿå·²å°±ç»ªï¼Œè¾“å‡ºæ–‡ä»¶: {log_file}", flush=True)

logger = logging.getLogger(__name__)

def parse_arguments() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ')
    parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--dry-run', action='store_true', help='ä»…è·å–æ•°æ®')
    parser.add_argument('--stocks', type=str, help='æŒ‡å®šè‚¡ç¥¨ä»£ç ')
    parser.add_argument('--no-notify', action='store_true', help='ä¸å‘é€é€šçŸ¥')
    parser.add_argument('--single-notify', action='store_true', help='å•è‚¡æ¨é€')
    parser.add_argument('--workers', type=int, default=None, help='å¹¶å‘æ•°')
    parser.add_argument('--schedule', action='store_true', help='å®šæ—¶ä»»åŠ¡æ¨¡å¼')
    parser.add_argument('--market-review', action='store_true', help='ä»…å¤§ç›˜å¤ç›˜')
    parser.add_argument('--no-market-review', action='store_true', help='è·³è¿‡å¤ç›˜')
    parser.add_argument('--webui', action='store_true', help='å¯åŠ¨WebUI')
    parser.add_argument('--webui-only', action='store_true', help='ä»…å¯åŠ¨WebUI')
    return parser.parse_args()

def run_full_analysis(config: Config, args: argparse.Namespace, stock_codes: Optional[List[str]] = None):
    """æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
    try:
        if getattr(args, 'single_notify', False):
            config.single_stock_notify = True
        
        pipeline = StockAnalysisPipeline(config=config, max_workers=args.workers)
        
        # === [ç°ä»£æœåŠ¡] æ ¸å¿ƒæ”¹é€ åŒºï¼šå…¨é¢‘æ®µæ‰«æ ===
        if stock_codes is None:
            raw_list = getattr(config, 'stock_list', [])
            if isinstance(raw_list, str):
                stock_codes = [s.strip() for s in raw_list.split(',') if s.strip()]
            elif isinstance(raw_list, list):
                stock_codes = list(raw_list)
            else:
                stock_codes = []
            logger.info(f"[System] åŸºç¡€è‡ªé€‰è‚¡åŠ è½½: {len(stock_codes)} åª")
        
        # å¯åŠ¨æ¯ç­æ‰«æ
        if not args.dry_run:
            try:
                logger.info("ğŸ“¡ [ç°ä»£æœåŠ¡] å¯åŠ¨å…¨é¢‘æ®µæ‰«ææ¢å¤´...")
                panic_targets = scan_for_destruction(limit=3)
                added = 0
                for code in panic_targets:
                    if code not in stock_codes:
                        stock_codes.append(code)
                        added += 1
                        logger.info(f"â• [è‡ªåŠ¨æ•è·] {code} å·²åŠ å…¥æ¯ç­åˆ†æé˜Ÿåˆ—")
            except Exception as e:
                logger.error(f"âŒ æ‰«ææ¨¡å—æ•…éšœ: {e}")

        # è¿è¡Œåˆ†æ
        results = pipeline.run(
            stock_codes=stock_codes,
            dry_run=args.dry_run,
            send_notification=not args.no_notify
        )

        # å¤§ç›˜å¤ç›˜
        market_report = ""
        if config.market_review_enabled and not args.no_market_review:
            # å»¶è¿Ÿé˜²é™æµ
            time.sleep(getattr(config, 'analysis_delay', 2))
            review_result = run_market_review(
                notifier=pipeline.notifier,
                analyzer=pipeline.analyzer,
                search_service=pipeline.search_service
            )
            if review_result:
                market_report = review_result
        
        # ç»“æœæ‘˜è¦
        if results:
            logger.info("\n===== åˆ†æç»“æœæ‘˜è¦ =====")
            for r in results:
                logger.info(f"{r.name}({r.code}): {r.operation_advice}")
        
        logger.info("\nä»»åŠ¡æ‰§è¡Œå®Œæˆ")

    except Exception as e:
        logger.exception(f"åˆ†ææµç¨‹æ‰§è¡Œå¤±è´¥: {e}")

def start_bot_stream_clients(config: Config) -> None:
    pass # GitHub Action ç¯å¢ƒä¸éœ€è¦ Stream Client

def main() -> int:
    """ä¸»å…¥å£å‡½æ•°"""
    # å¼ºåˆ¶æ‰“å°å¯åŠ¨ä¿¡æ¯
    print("DEBUG: ğŸ”Œ [System] main() å‡½æ•°å·²å¯åŠ¨ï¼æ­£åœ¨åˆå§‹åŒ–...", flush=True)
    
    args = parse_arguments()
    config = get_config()
    setup_logging(debug=args.debug, log_dir=config.log_dir)
    
    logger.info("=" * 60)
    logger.info("Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ (ç°ä»£æœåŠ¡å®Œå…¨ä½“) å¯åŠ¨")
    logger.info("=" * 60)
    
    # éªŒè¯é…ç½®
    config.validate()
    
    # è§£æè‚¡ç¥¨åˆ—è¡¨
    stock_codes = None
    if args.stocks:
        stock_codes = [code.strip() for code in args.stocks.split(',') if code.strip()]
    
    try:
        if args.market_review:
            logger.info("æ¨¡å¼: ä»…å¤§ç›˜å¤ç›˜")
            # ... (ç®€åŒ–çš„å¤ç›˜é€»è¾‘)
            notifier = NotificationService()
            analyzer = GeminiAnalyzer(api_key=config.gemini_api_key) if config.gemini_api_key else None
            run_market_review(notifier, analyzer, None)
            return 0
        
        # æ­£å¸¸è¿è¡Œ
        run_full_analysis(config, args, stock_codes)
        return 0
        
    except Exception as e:
        logger.exception(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1

# ==========================================
# âš ï¸ è‹å¤©ï¼Œè¿™ä¸€å—æ˜¯ä½ ä¹‹å‰ç¼ºå¤±çš„å¯åŠ¨å¼€å…³ï¼
# ==========================================
if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        pass
    except Exception as e:
        print(f"Fatal Error: {e}")
        sys.exit(1)
